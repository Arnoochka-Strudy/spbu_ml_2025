{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_circles, make_blobs, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "SEED = 314159\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "\n",
    "data_path = \"/home/victor/Datasets/ml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Рассмотрим набор данных о качестве вина на основе различных химических показателей. Есть всего 6 значений качества, поэтому задачу проще всего решать классификацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'/'+\"winequality-red.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Несбалансированные данные\n",
    "Несбалансированные данные - это одна из наиболее распространенных проблем, с которой сталкиваются в машинном обучении. Они возникают, когда классы, которые мы пытаемся предсказать, представлены неравномерно. Другими словами, один класс имеет гораздо меньше примеров, чем другой, что создает дисбаланс в распределении данных.\n",
    "Деревья решений очень уязвимы перед дисбалансом классов, так как используют вероятности в критериях разбиения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Определите, сколько в датасете примеров хорошего вина (оценка 7 и выше) и плохого (3) в процентах от общего количества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте новый признак \"good_quality\", чтобы выделить именно хорошее вино"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_quality'] = df['quality'] > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good_quality\n",
       "False    1382\n",
       "True      217\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.good_quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binarized = (df['quality'] > 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "_, _, y_train_b, y_test_b = train_test_split(X, y_binarized, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is:  1.0\n",
      "Test score is:  0.715625\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is:  1.0\n",
      "Test score is:  1.0\n"
     ]
    }
   ],
   "source": [
    "model_b = DecisionTreeClassifier(random_state=0)\n",
    "model_b.fit(X_train, y_train_b)\n",
    "print(\"Train score is: \", model_b.score(X_train, y_train_b))\n",
    "print(\"Test score is: \", model_b.score(X_test, y_test_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Метрики\n",
    "Так как данные несбалансированные, уместно ли использовать встроенное значение score для оценки модели? На самом деле, и да и нет, так как score возвращает усредненную точность по классам. Однако еще более информатиными будут F1-мера и другие более подробные оценки.\n",
    "Формула Precision:\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{\\text{TP}}{ \\text{TP} + \\text{FP} }\n",
    "\\end{equation}\n",
    "Precision наиболее полезна, если цена FP велика. Примеры такой задачи - детекция спама. В случае, если полезное письмо попадет в спам, юзер может потерять важную информацию, что нежелательно.\n",
    "Формула Recall:\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "Recall наиболее полезна, если цена FN велика. Она поможет, если нам необходимо найти всех больных пациентов, определить фрод и т.д.\n",
    "Вопрос: что отражают две эти метрики?\n",
    "\n",
    "\n",
    "Формула F1-метрики:\n",
    "\\begin{equation}\n",
    "\\text{F1} = \\frac{2 * \\text{TP}}{2 * \\text{TP} + \\text{FP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "F1-метрика может быть выведена из precision и recall и позволяет найти баланс между ними. \n",
    "\n",
    "**Задание**: определите, как f1 выводится из precision и recall.\n",
    "\n",
    "Существует и болеее общая оценка - $F_\\beta$. Она позволяет получить взвешенное среднее между precision и recall. Ее формулу дадим на занятии. Наиболее популярные параметры - 2 и 0.5.\n",
    "Тут тоже есть особенности. Метрики бывают нескольких видов, в зависимости от того, как учитываются разные классы:\n",
    "- микро - метрики считаются глобально сразу по всем классам.\n",
    "- макро - вначале считаются для каждого класса, потом берется среднее\n",
    "- взвешенные по классам - вначале считаются для каждого класса, потом берется среднее, взвешенное по поддержке\n",
    "\n",
    "Вопрос: какой способ вычисления лучше всего выбрать при дисбалансе классов? Покажите на примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to write something on whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1-score is:  1.0\n",
      "Test f1-score is:  0.4676044863032091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Train f1-score is: \", f1_score(y_train, model.predict(X_train), average=\"micro\"))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, model.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1-score (binary) is:  1.0\n",
      "Test f1-score  (binary) is:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train f1-score (binary) is: \", f1_score(y_train_b, model_b.predict(X_train), average=\"micro\"))\n",
    "print(\"Test f1-score  (binary) is: \", f1_score(y_test_b, model_b.predict(X_test), average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get macro metrics for basic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get macro metrics for binarized prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Давайте руками рассмотрим, как оценивается точность и почему нам сложно получить адекватную оценку при сильном дисбалансе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['label', 'TP', 'TN', 'FP', 'FN', 'support', 'accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Закончите код для рассчета метрик по классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for class_id in classes:\n",
    "    class_stats = {}\n",
    "    gt = X_test.loc[y_test==class_id]\n",
    "    class_stats[\"support\"] = len(gt)\n",
    "    ########### YOUR CODE\n",
    "    # get model predictions\n",
    "    # calculate number of TP, FP, TN and FN for this class using filtering\n",
    "    # Use provided metrics to calculate accuracy, precision and recall    \n",
    "    ########### YOUR CODE\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame(class_stats, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Посчитайте макро-метрики. \n",
    "\n",
    "**Задание со звездочкой**: Посчитайте микро-метрики. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imbalanced learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Как заставить модель учиться так, чтобы учитывать все классы? Самое простое - задать вес класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: Какие есть хорошие способы это сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class_weights =  # your code: set the list of weights of your choice\n",
    "model = DecisionTreeClassifier(class_weight={classes[i]: w for i, w in enumerate(class_weights)}, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the classifier with weights for binarized case too.  Output it's internal scores for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output train/test micro and macro f1 scores for weighted and unweighted trees (all classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output train/test micro and macro f1 scores for weighted and unweighted trees (binarized classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Выведем, как изменились предсказания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create new dataframe with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Также посмотрим, насколько чувствительна к дисбалансу другая модель - LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and Logreg\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Naive train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Naive test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Classes\", logreg.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and Logreg with class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Balanced train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Balanced test score is: \", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "То же самое можно сделать с использованием итеративного линейного классификатора. Используем для этого SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "logreg = # make pipeline of Scaler and SGDClassifier without class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Naive train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Naive test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Naive test f1-score is: \", f1_score(y_test, y_pred=logreg.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and SGDClassifier with class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Balanced train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Balanced test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Balanced test f1-score is: \", f1_score(y_test, y_pred=logreg.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Обучите более сильный классификатор (RF, GB). Постройте confusion matrix, выведите скоры для него с балансировкой и без. Ответьте на вопрос, как соотносится чувствительность более сильных классификаторов к дисбалансу с более слабыми.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Как видно, балансировка не всегда одинаково полезна. Однако мы можем попробовать воспользоваться дополнительными методами для обучения нашего дерева. Это будет андер- и оверсемплинг (балансировка датасета). Самое простое - взять только небольшую, но сбалансированную часть обучающих данных для непосредственного обучения. Однако, для нашего случая это плохо подходит, так как данных довольно мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Еще раз вспомним, какие предсказания давало дерево решений для нашего набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оверсемплинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала проведем простейший оверсемплинг, выбирая семплы из минорного класса с заменой до достижения баланса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts(y) -> None:\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(\"\\n\".join([f\"{u}: {c}\" for u, c in zip(unique, counts)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen, y_gen = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.02, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=SEED)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gen, y_gen) # train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain score is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mscore(\u001b[43mX_res\u001b[49m, y_res))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest score is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest f1-score is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_score(y_test, y_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X_test), average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_res' is not defined"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=SEED, ) # choose your parameters\n",
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))\n",
    "print_counts(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=SEED, ) # choose your parameters\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))\n",
    "print_counts(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### SMOTE (Synthetic Minority Oversampling Technique):\n",
    "SMOTE позволяет расширить выборку, построив синтетические примеры на основе уже существующих. Это еще один вариант решения «проблем классового дисбаланса».\n",
    "\n",
    "Общая схема SMOTE:\n",
    "1) Для создания нового семпла используют пару признаков «соседних» примеров a  и b из миноритарного класса. Их находят, используя алгоритм ближайшего соседа KNN. В данном случае необходимо и достаточно для семпла a получить набор из k соседей, из которого в дальнейшем будет случайно выбран семпл b.\n",
    "2) Для создания нового семпла находят разность $d=X_b–X_a$, где $X_a,X_b$ – векторы признаков «соседних» примеров a  и b из миноритарного класса.\n",
    "3) Далее из $d$ путем его умножения на случайное число в интервале (0,1)  получают $d'$.\n",
    "4) Вектор признаков нового примера вычисляется путем сложения Xa и $d'$.\n",
    "\n",
    "Вопрос: сколько соседей выбирать? И сколько соседей стоит использовать для каждой узловой точки?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "print_counts(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "print_counts(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Также мы можем получить более подробный отчет по точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Рассмотрим также то, как разные алгоритмы принимают решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=SEED)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Choosing the first 2 columns for the plot\n",
    "\n",
    "def get_decision_boundary(X_train, y_train, features, ax=None, model=\"logistic\"):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "    # Creating and fitting the tree classifier\n",
    "    if model == \"logistic\":\n",
    "        classifier = LogisticRegression() # your code: \n",
    "    else:\n",
    "        classifier = RandomForest() # your code: choose another one\n",
    "    # your code: fit model\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Plotting the tree boundaries\n",
    "    plot_decision_function(X_train, y_train, classifier, ax)\n",
    "\n",
    "    # Plotting the data points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], alpha=0.8, c=y_train, edgecolor='k')\n",
    "    plt.title(f\"Decision surface for {classifier.__class__.__name__} on {features[0]} and {features[1]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "get_decision_boundary(X_train, y_train, features = ['x1', 'x2' ], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED, k_neighbors=4)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Введем еще один метод оверсемплинга - AdaSYN (Adaptive Synthetic). Этот алгоритм, в отличие от ресэмплинга и SMOTE позволяет сгенерировать более \"сложные\" примеры.\n",
    "Этот алгоритм работает следующим образом:\n",
    "1) Рассчитывается отношение миноритарного и мажоритарного класса: $d = m_s / m_l $\n",
    "2) Определяется, сколько элементов необходимо нагенерировать: $G = (m_l - m_s) * \\beta $. $\\beta $ - параметр балансировки\n",
    "3) Для каждого семпла из миноритарного класса находятся k соседей. После чего ему присваивается вес $r_i = num_major_neighbours / k $.\n",
    "4) $r_i$ нормализуются так, чтобы их сумма равнялсь 1: $ {r_i}' =  \\frac {r_i} {\\sum{r_j}$\n",
    "5) Для каждого семпла определяется число сгененрированных примеров.  $G_i = G * {r_i}' $. Вопрос: в каких областях будет генерироваться больше примеров?\n",
    "6) Далее для каждого примера и его соседей генерируется синтетический пример, как в SMOTE. Также может быть использована добавка белого шума.\n",
    "\n",
    "Вопрос: какие минусы у SMOTE и AdaSYN по отношению друг к другу?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "smote = ADASYN(random_state=SEED) # your parameters\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "На графике сразу видно, когда AdaSYN  может помешать хорошей генерации. Как видно, так как AdaSYN концентрирует сгенерированные примеры у границ классов, тогда как SMOTE может \"соединять\" и примеры в центральной части класса, то он может быть более удачным методом. К тому же, сущестуют различные вариации SNOTE, которые могут давать хороший рещультат в такой постановке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(random_state=SEED) # your parameters\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Вопрос: какие можно еще придумать более \"умные\" варианты оверсемплинга на основе CMOTE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Задание:** Примените разные алгоритмы на данных с вином. Помогает ли оверсемплинг для работы слабых и сильных моделей? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Уменьшение выборки (андерсемплинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Prototype generation\n",
    "Методы Prototype generation (создания прототипов) позволяют сократить количество объектов в целевых классах, но остальные объекты генерируются, а не выбираются, из исходного набора.\n",
    "ClusterCentroids использует для этого KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "sampler = ClusterCentroids(random_state=SEED, estimator=KMeans())# your parameters)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "sampler = ClusterCentroids(random_state=SEED, estimator=KMeans())# your parameters)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Prototype selection\n",
    "Алгоритмы Prototype selection (выбора прототипов) можно разделить на две группы: (i) методы контролируемой недостаточной выборки и (ii) методы очистки недостаточной выборки.\n",
    "\n",
    "Эти методы сокращают количество примеров в мажоритарных классах до произвольного размера, указанного пользователем. Обычно они сводят количество наблюдений к размеру миноритарного класса(ов).\n",
    "К ним относятся: Random UnderSampling, NearMiss.\n",
    "Prototype selection «очищают» пространство признаков, удаляя либо «зашумленные», либо «слишком легко классифицируемые» наблюдения, в зависимости от метода. Окончательное количество наблюдений в каждом классе зависит от метода очистки и не может быть указано пользователем.\n",
    "К ним относится, например, метод связей Томека.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Наиболее простой метод - RandomUnderSampler - просто выкидывает семплы случайным образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Попробуйте реализовать такой семплер вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "NearMiss добавляет некоторые эвристики для выбора семплов. Так, он может выбирать для удаления примеры, ближайшие к миноритарном классу, примеры, среднее расстояние у которых до наиболее дальних примеров из миноритарного класса наименьшее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# you can add some figures with nearmiss undersampling (use imblearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Связь Томека существует, когда два примера из разных классов являются ближайшими соседями друг к другу. Алгоритм связей Томека детектирует такие связи и удаляет пример из мажоритарного класса. Основная идея заключается в том, что связи Томека зашумлены или наблюдения трудно классифицировать, и поэтому они не помогут алгоритму найти подходящую границу разделения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# your сode (use imblearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Edited nearest neighbours - для примеров из миноритарного класса находит k ближайших соседей и удаляет все семплы из мажоритарных классов, попавшие в эту окрестность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# your code (use imblearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
